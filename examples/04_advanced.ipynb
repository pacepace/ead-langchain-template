{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f8cec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Example 04: Advanced Features\n",
    "\n",
    "This example demonstrates advanced LangChain features for production use:\n",
    "- Token counting and cost tracking with callbacks\n",
    "- Response metadata inspection\n",
    "- Error handling and retries\n",
    "- Batch processing\n",
    "- Model parameters tuning\n",
    "\n",
    "These features are optional but useful when building production applications.\n",
    "\n",
    "Using most cost-effective models as of October 2025:\n",
    "  gpt-5-nano, claude-3-haiku-20240307, gemini-2.0-flash-lite\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b86193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72161478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third-party imports\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.callbacks import BaseCallbackHandler\n",
    "from langchain_core.outputs import LLMResult\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4330238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local imports\n",
    "from langchain_llm import get_api_key, get_logger, get_model_name, load_env_config, setup_logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee88951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging and configuration\n",
    "setup_logging()\n",
    "logger = get_logger(__name__)\n",
    "load_env_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b259405",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenCounterCallback(BaseCallbackHandler):\n",
    "    \"\"\"\n",
    "    Custom callback to track token usage and estimate costs.\n",
    "\n",
    "    LangChain callbacks allow you to hook into LLM lifecycle\n",
    "    and track metrics like tokens, latency, and costs.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize token tracker.\n",
    "        \"\"\"\n",
    "        self.total_tokens = 0\n",
    "        self.prompt_tokens = 0\n",
    "        self.completion_tokens = 0\n",
    "        self.total_cost = 0.0\n",
    "\n",
    "        # Approximate pricing (as of October 2025 - check current pricing!)\n",
    "        self.pricing = {\n",
    "            \"gpt-5-nano\": {\"prompt\": 0.05 / 1000, \"completion\": 0.40 / 1000},\n",
    "            \"claude-3-haiku-20240307\": {\"prompt\": 0.25 / 1000, \"completion\": 1.25 / 1000},\n",
    "            \"gemini-2.0-flash-lite\": {\"prompt\": 0.07 / 1000, \"completion\": 0.30 / 1000},\n",
    "        }\n",
    "\n",
    "    def on_llm_end(self, response: LLMResult, **kwargs) -> None:\n",
    "        \"\"\"\n",
    "        Called when LLM finishes running.\n",
    "\n",
    "        :param response: LLM result containing outputs and metadata\n",
    "        :ptype response: LLMResult\n",
    "        :param kwargs: Additional keyword arguments\n",
    "        :return: None\n",
    "        :rtype: None\n",
    "        \"\"\"\n",
    "        # Extract token usage from response metadata\n",
    "        if response.llm_output and \"token_usage\" in response.llm_output:\n",
    "            usage = response.llm_output[\"token_usage\"]\n",
    "            prompt_tokens = usage.get(\"prompt_tokens\", 0)\n",
    "            completion_tokens = usage.get(\"completion_tokens\", 0)\n",
    "            total_tokens = usage.get(\"total_tokens\", 0)\n",
    "\n",
    "            self.prompt_tokens += prompt_tokens\n",
    "            self.completion_tokens += completion_tokens\n",
    "            self.total_tokens += total_tokens\n",
    "\n",
    "            # Estimate cost (if model is known)\n",
    "            model = response.llm_output.get(\"model_name\", \"\")\n",
    "            if model in self.pricing:\n",
    "                cost = (prompt_tokens * self.pricing[model][\"prompt\"]) + (completion_tokens * self.pricing[model][\"completion\"])\n",
    "                self.total_cost += cost\n",
    "\n",
    "    def get_summary(self) -> dict[str, int | float]:\n",
    "        \"\"\"\n",
    "        Get summary of token usage and costs.\n",
    "\n",
    "        :return: Dictionary with token counts and estimated cost\n",
    "        :rtype: dict[str, int | float]\n",
    "        \"\"\"\n",
    "        return {\n",
    "            \"total_tokens\": self.total_tokens,\n",
    "            \"prompt_tokens\": self.prompt_tokens,\n",
    "            \"completion_tokens\": self.completion_tokens,\n",
    "            \"estimated_cost_usd\": round(self.total_cost, 6),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e945524a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_tracking_example():\n",
    "    \"\"\"\n",
    "    Demonstrate token counting and cost tracking using callbacks.\n",
    "    \"\"\"\n",
    "    logger.info(\"Running token tracking example\")\n",
    "\n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    print(\"Token Tracking & Cost Estimation\")\n",
    "    print(f\"{'=' * 80}\\n\")\n",
    "\n",
    "    api_key = get_api_key(\"openai\")\n",
    "\n",
    "    # Create callback instance\n",
    "    token_counter = TokenCounterCallback()\n",
    "\n",
    "    # Pass callbacks to the LLM\n",
    "    # NOTE: GPT-5 models require temperature=1 (except gpt-5-chat-latest which supports other values)\n",
    "    llm = ChatOpenAI(\n",
    "        model=get_model_name(\"openai\") or \"gpt-5-nano\",\n",
    "        api_key=api_key,\n",
    "        temperature=1.0,\n",
    "        callbacks=[token_counter],  # Attach our callback\n",
    "    )\n",
    "\n",
    "    # Make several calls\n",
    "    prompts = [\n",
    "        \"What is machine learning?\",\n",
    "        \"Explain neural networks in one sentence.\",\n",
    "        \"What is the difference between AI and ML?\",\n",
    "    ]\n",
    "\n",
    "    for i, prompt in enumerate(prompts, 1):\n",
    "        print(f\"Query {i}: {prompt}\")\n",
    "        response = llm.invoke(prompt)\n",
    "        print(f\"Response: {response.content[:100]}...\\n\")\n",
    "\n",
    "    # Get usage summary\n",
    "    summary = token_counter.get_summary()\n",
    "    print(\"-\" * 80)\n",
    "    print(\"Token Usage Summary:\")\n",
    "    print(f\"  Total tokens: {summary['total_tokens']}\")\n",
    "    print(f\"  Prompt tokens: {summary['prompt_tokens']}\")\n",
    "    print(f\"  Completion tokens: {summary['completion_tokens']}\")\n",
    "    print(f\"  Estimated cost: ${summary['estimated_cost_usd']:.6f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try This\n",
    "\n",
    "Experiment with the code above:\n",
    "1. Experiment with different models: `gpt-4o`, `gpt-5-mini`, or `gpt-5`\n",
    "2. Modify the prompt to ask about a topic relevant to your work\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Your experiments here\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4a28ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metadata_inspection_example():\n",
    "    \"\"\"\n",
    "    Inspect response metadata to understand model behavior.\n",
    "    \"\"\"\n",
    "    logger.info(\"Running metadata inspection example\")\n",
    "\n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    print(\"Response Metadata Inspection\")\n",
    "    print(f\"{'=' * 80}\\n\")\n",
    "\n",
    "    api_key = get_api_key(\"anthropic\")\n",
    "    llm = ChatAnthropic(model=get_model_name(\"anthropic\") or \"claude-3-haiku-20240307\", api_key=api_key, temperature=0.7)\n",
    "\n",
    "    # Get response with metadata\n",
    "    response = llm.invoke(\"Explain what metadata is in one sentence.\")\n",
    "\n",
    "    print(f\"Response: {response.content}\\n\")\n",
    "    print(\"Response Metadata:\")\n",
    "    print(f\"  Model: {response.response_metadata.get('model', 'N/A')}\")\n",
    "    print(f\"  Stop reason: {response.response_metadata.get('stop_reason', 'N/A')}\")\n",
    "\n",
    "    # Token usage (if available)\n",
    "    usage = response.response_metadata.get(\"usage\", {})\n",
    "    if usage:\n",
    "        print(f\"  Input tokens: {usage.get('input_tokens', 'N/A')}\")\n",
    "        print(f\"  Output tokens: {usage.get('output_tokens', 'N/A')}\")\n",
    "\n",
    "    # Additional fields vary by provider\n",
    "    print(f\"  Additional metadata: {list(response.response_metadata.keys())}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try This\n",
    "\n",
    "Experiment with the code above:\n",
    "1. Try changing the `temperature` parameter (0.0 for deterministic, 1.0 for creative)\n",
    "2. Try different Claude models: `claude-3-5-sonnet-20241022`, `claude-haiku-4-5`\n",
    "3. Modify the prompt to ask about a topic relevant to your work\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Your experiments here\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c60fc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retry_and_error_handling_example():\n",
    "    \"\"\"\n",
    "    Demonstrate error handling and retry patterns.\n",
    "    \"\"\"\n",
    "    logger.info(\"Running retry and error handling example\")\n",
    "\n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    print(\"Error Handling & Retry Logic\")\n",
    "    print(f\"{'=' * 80}\\n\")\n",
    "\n",
    "    api_key = get_api_key(\"openai\")\n",
    "    # NOTE: GPT-5 models require temperature=1 (except gpt-5-chat-latest which supports other values)\n",
    "    llm = ChatOpenAI(\n",
    "        model=get_model_name(\"openai\") or \"gpt-5-nano\",\n",
    "        api_key=api_key,\n",
    "        temperature=1.0,\n",
    "        max_retries=3,  # LangChain has built-in retry logic!\n",
    "        request_timeout=30,  # Timeout after 30 seconds\n",
    "    )\n",
    "\n",
    "    # Example: Handling failures gracefully\n",
    "    prompts = [\"What is Python?\", \"Explain JavaScript briefly.\"]\n",
    "\n",
    "    for prompt in prompts:\n",
    "        try:\n",
    "            print(f\"Query: {prompt}\")\n",
    "            response = llm.invoke(prompt)\n",
    "            print(f\"[SUCCESS] Response: {response.content[:80]}...\\n\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to get response: {e}\")\n",
    "            print(f\"[ERROR] Error: {e}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try This\n",
    "\n",
    "Experiment with the code above:\n",
    "1. Experiment with different models: `gpt-4o`, `gpt-5-mini`, or `gpt-5`\n",
    "2. Modify the prompt to ask about a topic relevant to your work\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Your experiments here\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103942ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_processing_example():\n",
    "    \"\"\"\n",
    "    Process multiple prompts using LangChain's batch method.\n",
    "\n",
    "    Note: LangChain's batch() makes separate API calls (potentially in parallel)\n",
    "    for each prompt. This is different from API-level batching which would\n",
    "    send all prompts in a single request. The benefit is convenience and\n",
    "    potential parallelization, not reduced API calls.\n",
    "    \"\"\"\n",
    "    logger.info(\"Running batch processing example\")\n",
    "\n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    print(\"Batch Processing\")\n",
    "    print(f\"{'=' * 80}\\n\")\n",
    "\n",
    "    api_key = get_api_key(\"openai\")\n",
    "    # NOTE: GPT-5 models require temperature=1 (except gpt-5-chat-latest which supports other values)\n",
    "    llm = ChatOpenAI(model=get_model_name(\"openai\") or \"gpt-5-nano\", api_key=api_key, temperature=1.0)\n",
    "\n",
    "    # Multiple prompts to process\n",
    "    prompts = [\n",
    "        \"What is Python?\",\n",
    "        \"What is JavaScript?\",\n",
    "        \"What is Rust?\",\n",
    "    ]\n",
    "\n",
    "    print(\"Processing 3 prompts in batch...\\n\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # LangChain's batch() method processes multiple prompts\n",
    "    # Makes separate API calls (one per prompt) but provides convenient interface\n",
    "    # Pass strings directly - LangChain wraps them in messages internally\n",
    "    responses = llm.batch(prompts)\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "\n",
    "    for prompt, response in zip(prompts, responses):\n",
    "        print(f\"Q: {prompt}\")\n",
    "        print(f\"A: {response.content[:80]}...\\n\")\n",
    "\n",
    "    print(f\"Processed {len(prompts)} prompts in {elapsed:.2f} seconds\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try This\n",
    "\n",
    "Experiment with the code above:\n",
    "1. Experiment with different models: `gpt-4o`, `gpt-5-mini`, or `gpt-5`\n",
    "2. Try adding more prompts to the batch and compare timing\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Your experiments here\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd663d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def advanced_parameters_example():\n",
    "    \"\"\"\n",
    "    Demonstrate advanced model parameters for fine-tuning behavior.\n",
    "\n",
    "    NOTE: GPT-5 models (gpt-5-nano, gpt-5-mini, gpt-5) have limited parameter support.\n",
    "    They only support temperature=1.0 and do not support top_p or other tuning parameters.\n",
    "    Use gpt-5-chat-latest or gpt-4o models for full parameter control.\n",
    "    \"\"\"\n",
    "    logger.info(\"Running advanced parameters example\")\n",
    "\n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    print(\"Advanced Model Parameters\")\n",
    "    print(f\"{'=' * 80}\\n\")\n",
    "\n",
    "    api_key = get_api_key(\"openai\")\n",
    "\n",
    "    # GPT-5 models support max_tokens but not temperature/top_p variations\n",
    "    # Demonstrating max_tokens to control response length\n",
    "    token_limits = [20, 50]\n",
    "    prompt = \"Write a creative opening line for a sci-fi story.\"\n",
    "\n",
    "    for max_tok in token_limits:\n",
    "        llm = ChatOpenAI(\n",
    "            model=get_model_name(\"openai\") or \"gpt-5-nano\",\n",
    "            api_key=api_key,\n",
    "            temperature=1.0,  # GPT-5 requires temperature=1\n",
    "            max_tokens=max_tok,  # Limit response length\n",
    "        )\n",
    "\n",
    "        response = llm.invoke(prompt)\n",
    "        print(f\"Max tokens: {max_tok}\")\n",
    "        print(f\"  {response.content}\\n\")\n",
    "\n",
    "    # For full parameter control, use gpt-5-chat-latest or gpt-4o:\n",
    "    # llm = ChatOpenAI(\n",
    "    #     model=\"gpt-5-chat-latest\",  # or \"gpt-4o\"\n",
    "    #     api_key=api_key,\n",
    "    #     temperature=0.7,  # Custom temperature supported\n",
    "    #     top_p=0.9,  # Nucleus sampling supported\n",
    "    #     max_tokens=100,\n",
    "    # )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try This\n",
    "\n",
    "Experiment with the code above:\n",
    "1. Experiment with different models: `gpt-4o`, `gpt-5-mini`, or `gpt-5`\n",
    "2. Modify the prompt to ask about a topic relevant to your work\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Your experiments here\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15d6d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Run all advanced examples.\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"Example 04: Advanced Features\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"\\nThese examples show advanced features for production applications.\")\n",
    "    print(\"Start simple (examples 01-03) and add these features as needed.\")\n",
    "    print()\n",
    "\n",
    "    try:\n",
    "        token_tracking_example()\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Token tracking example failed: {type(e).__name__}: {e}\")\n",
    "        print(f\"[ERROR] Token tracking example failed ({type(e).__name__}): {e}\\n\")\n",
    "\n",
    "    try:\n",
    "        metadata_inspection_example()\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Metadata inspection example failed: {type(e).__name__}: {e}\")\n",
    "        print(f\"[ERROR] Metadata inspection example failed ({type(e).__name__}): {e}\\n\")\n",
    "\n",
    "    try:\n",
    "        retry_and_error_handling_example()\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Retry example failed: {type(e).__name__}: {e}\")\n",
    "        print(f\"[ERROR] Retry example failed ({type(e).__name__}): {e}\\n\")\n",
    "\n",
    "    try:\n",
    "        batch_processing_example()\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Batch processing example failed: {type(e).__name__}: {e}\")\n",
    "        print(f\"[ERROR] Batch processing example failed ({type(e).__name__}): {e}\\n\")\n",
    "\n",
    "    try:\n",
    "        advanced_parameters_example()\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Advanced parameters example failed: {type(e).__name__}: {e}\")\n",
    "        print(f\"[ERROR] Advanced parameters example failed ({type(e).__name__}): {e}\\n\")\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(\"[SUCCESS] Advanced examples complete!\")\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457d954c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}